---
title: "Practical Machine Learning"
author: "Oscar Legat"
date: "31 de enero de 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Loading the necessary libraries

These are the libraries needed to execute correctly the Rmd Script.


```{r}
library(caret)
library(randomForest)
library(caret)
library(e1071)
```


## Loading data

```{r}
trainUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

valUrl <- "http://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

data <- read.csv(url(trainUrl), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))

validation <- read.csv(url(valUrl), header=TRUE, sep=",", na.strings=c("NA","#DIV/0!",""))

```

## Removing some features

From explanation of the data, has been deducted that the following features have to be removed.

```{r}
data <- data[, -seq(1:7)]
validation <- validation[, -seq(1:7)]

```


## Detecting missing data and treatment

To treat missing data, first try to detect NAs and proportions of those. We will considerer not usefull
the feature if the porcentage of Nas is greater than 70%.


```{r}

propmiss <- function(dataframe) {
  m <- sapply(dataframe, function(x) {
    data.frame(
      nmiss=sum(is.na(x)), 
      n=length(x), 
      propmiss=sum(is.na(x))/length(x)
    )
  })
  d <- data.frame(t(m))
  d <- sapply(d, unlist)
  d <- as.data.frame(d)
  d$variable <- row.names(d)
  row.names(d) <- NULL
  d <- cbind(d[ncol(d)],d[-ncol(d)])
  return(d[order(d$propmiss), ])
}

missData <- propmiss(data)

str(missData)

missDataVars <- missData[missData$propmiss > 0.70,]$variable
data <- data[, !names(data)%in%missDataVars]
validation <- validation[, !names(validation)%in%missDataVars]

```

## Detecting strong correlations and treatment

We are insterested in remove those variables that are strongly correlated. We consider strong correlation if it is equal or greater than 0.9 .

```{r}


last <- as.numeric(ncol(data))
penultimate <- last - 1

for (i in 1:penultimate) {
  data[,i] <- as.numeric(data[,i])
  validation[,i] <- as.numeric(validation[,i])
}

strong_correlations <- findCorrelation(cor(data[, -c(last)]), cutoff=0.9)

data <- data[, -strong_correlations]
validation <- validation[, -strong_correlations]

```

##Before to train the model, preprocessing features

```{r}

last <- as.numeric(ncol(data))

preObj <-preProcess(data[,-c(last)],method=c('knnImpute', 'center', 'scale'))
dataPrep <- predict(preObj, data[,-c(last)])
dataPrep$classe <- data$classe

valPrep <-predict(preObj,validation[,-c(last)])
valPrep$problem_id <- validation$problem_id

```


### Train the model

```{r}

inTrain <- createDataPartition(y=dataPrep$classe, p=0.7, list=FALSE )
training <- dataPrep[inTrain,]
testing <- dataPrep[-inTrain,]


# set seed for reproducibility
set.seed(12345)


last <- as.numeric(ncol(training))

# get the best mtry
bestmtry <- tuneRF(training[,-c(last)],training$classe, ntreeTry=100, 
                   stepFactor=1.5, trace=TRUE, plot=TRUE, dobest=FALSE)

mtry <- bestmtry[as.numeric(which.min(bestmtry[,"OOBError"])),"mtry"]

#Random Forest training
rdf <-randomForest(classe~.,data=training, mtry=mtry, ntree=501, 
                      keep.forest=TRUE, proximity=TRUE, 
                      importance=TRUE,test=testing)

```


## Acuraccy results

```{r}

pred_training <- predict(rdf, newdata = training)
postResample(pred_training, training$classe)
pred_testing <- predict(rdf, newdata = testing)
postResample(pred_testing, testing$classe)

```


## Predictions for answer
```{r}
answer<-predict(rdf,valPrep)
answer
```


